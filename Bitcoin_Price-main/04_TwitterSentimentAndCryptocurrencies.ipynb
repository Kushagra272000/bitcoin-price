{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis between the Bitcoin currency and Twitter\n",
    "\n",
    "This project consists of a correlation analysis between the Bitcoin currency and tweets. In order to define the positiveness of a tweet (if the course of the bitcoin will go up or down), we realise a sentiment analysis of each tweet using the VADER algorithm. Finally we try to find a correlation between the two and we will make some machine learning to make predictions.\n",
    "\n",
    "This notebook was written using Python 3.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Python dependencies\n",
    "For this project we need Pandas to manage all of our datasets.\n",
    "\n",
    "You will need to run the following commands with pip to install the dependencies:\n",
    "\n",
    "```\n",
    "pip install VaderSentiment\n",
    "pip install pandas\n",
    "pip install tqdm\n",
    "...\n",
    "```\n",
    "\n",
    "You can also run `pip install .` from the project's root folder to install all the requirements from the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import glob\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the currency and the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the currency\n",
    "#CURRENCY = \"zilliqa\"\n",
    "#CURRENCY_SYMBOL = \"ZIL\"\n",
    "#CURRENCY = \"nexo\"\n",
    "#CURRENCY_SYMBOL = \"NEXO\"\n",
    "CURRENCY = \"bitcoin\"\n",
    "CURRENCY_SYMBOL = \"BTC\"\n",
    "\n",
    "CRYPTO_FOLDER = \"data/crypto/\"+CURRENCY_SYMBOL\n",
    "TWITTER_FOLDER = \"data/twitter/\"+CURRENCY_SYMBOL\n",
    "\n",
    "#tweets_clean_file = f'{TWITTER_FOLDER}/{CURRENCY}_tweets_clean.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "We read the data generated from two other notebooks, TwitterExtraction and CryptoCurrencyExtraction. The extraction process is detailed in these notebooks so please refer to them for any information needed. Here we simply gather all the extracted data to generate two datasets :\n",
    "\n",
    "- The twitter dataset : contains historical tweets related to the targeted crypto currency with a sentiment score.\n",
    "- The crypo dataset : contains historical data of the crypto currency we target with the change in USD.\n",
    "\n",
    "### Twitter dataset\n",
    "\n",
    "The data is split into multiple files. Here it is gathered into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet shape before droping duplicates (21224864, 9)\n",
      "tweet shape after droping duplicates (2556362, 9)\n",
      "duplicates removed 18668502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>UserName</th>\n",
       "      <th>UserFollowerCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>Likes</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>compound</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375226282036764674</td>\n",
       "      <td>RT : This is what happens to Bitcoin when opti...</td>\n",
       "      <td>Ronald</td>\n",
       "      <td>21</td>\n",
       "      <td>1103</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Mar 25 23:21:10 +0000 2021</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-6.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1375226284859662339</td>\n",
       "      <td>ðŸ”„ Prices update in $USD (1 hour):$BTC - 51784....</td>\n",
       "      <td>Cryptocurrencies / USD</td>\n",
       "      <td>5244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Mar 25 23:21:11 +0000 2021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                               Text  \\\n",
       "0  1375226282036764674  RT : This is what happens to Bitcoin when opti...   \n",
       "3  1375226284859662339  ðŸ”„ Prices update in $USD (1 hour):$BTC - 51784....   \n",
       "\n",
       "                 UserName  UserFollowerCount  RetweetCount  Likes  \\\n",
       "0                  Ronald                 21          1103      0   \n",
       "3  Cryptocurrencies / USD               5244             0      0   \n",
       "\n",
       "                        CreatedAt  compound  score  \n",
       "0  Thu Mar 25 23:21:10 +0000 2021    -0.296 -6.512  \n",
       "3  Thu Mar 25 23:21:11 +0000 2021     0.000  0.000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweets = pd.read_csv(tweets_clean_file)\n",
    "twitter_files = glob.glob(TWITTER_FOLDER+\"/*~*.csv\")\n",
    "twitter_files = sorted(twitter_files)\n",
    "\n",
    "dfs = []\n",
    "for file in twitter_files:\n",
    "    dfs.append(pd.read_csv(file))\n",
    "tweets = pd.concat(dfs)\n",
    "#tweets = tweets.sort_values(by=['ID'])\n",
    "\n",
    "# Drop duplicate tweets\n",
    "print('tweet shape before droping duplicates', tweets.shape)\n",
    "duplicates_removed = tweets.shape[0]\n",
    "tweets = tweets.drop_duplicates(subset=['ID'])\n",
    "duplicates_removed -= tweets.shape[0]\n",
    "print('tweet shape after droping duplicates', tweets.shape)\n",
    "print('duplicates removed', duplicates_removed)\n",
    "\n",
    "# Display dataframes head\n",
    "tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7806b4aa3067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcrypto_usd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcrypto_usd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrypto_usd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Drop duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5462\u001b[0m                 \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5464\u001b[0;31m             indexer = nargsort(\n\u001b[0m\u001b[1;32m   5465\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5466\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mnargsort\u001b[0;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mnon_nans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mnon_nan_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_nans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "CRYPTO_FOLDER = \"data/crypto/\"+CURRENCY_SYMBOL\n",
    "crypto_files = glob.glob(CRYPTO_FOLDER+\"/*.csv\")\n",
    "dfs = []\n",
    "for file in crypto_files:\n",
    "    dfs.append(pd.read_csv(file, parse_dates=['time']))\n",
    "crypto_usd = pd.concat(dfs)\n",
    "crypto_usd = crypto_usd.sort_values(by=['time'])\n",
    "\n",
    "# Drop duplicates\n",
    "print('bitcoin shape before droping duplicates', crypto_usd.shape)\n",
    "duplicates_removed = crypto_usd.shape[0]\n",
    "crypto_usd = crypto_usd.drop_duplicates(subset=['time'])\n",
    "print('bitcoin shape after droping duplicates', crypto_usd.shape)\n",
    "duplicates_removed -= crypto_usd.shape[0]\n",
    "print('duplicates removed', duplicates_removed)\n",
    "crypto_usd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by and sum by timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreatedAt\n",
      "2021-03-25 23:00:00    4.015421e+06\n",
      "2021-03-26 00:00:00    5.786594e+08\n",
      "2021-03-26 01:00:00    2.684363e+08\n",
      "2021-03-26 02:00:00    1.650798e+08\n",
      "2021-03-26 03:00:00    7.260512e+08\n",
      "                           ...     \n",
      "2021-04-26 05:00:00    5.369770e+07\n",
      "2021-04-26 06:00:00    3.170949e+07\n",
      "2021-04-26 07:00:00    6.056030e+07\n",
      "2021-04-26 08:00:00    4.735721e+06\n",
      "2021-04-26 09:00:00    2.647120e+06\n",
      "Freq: H, Name: score, Length: 755, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unit='s' not valid with non-numerical val='2021-03-25 07:00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9ac6d083f6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_grouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtweets_grouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/twitter/BTC/bitcoin_tweets_grouped.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcrypto_usd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrypto_usd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcrypto_usd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrypto_usd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             result, tz_parsed = tslib.array_with_unit_to_datetime(\n\u001b[0m\u001b[1;32m    346\u001b[0m                 \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             )\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_with_unit_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unit='s' not valid with non-numerical val='2021-03-25 07:00:00'"
     ]
    }
   ],
   "source": [
    "tweets['CreatedAt'] = pd.to_datetime(tweets['CreatedAt'])\n",
    "tweets['CreatedAt'] = tweets['CreatedAt'].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tweets['CreatedAt'] = pd.to_datetime(tweets['CreatedAt'])\n",
    "tweets.index = tweets['CreatedAt']\n",
    "\n",
    "tweets_grouped = tweets.groupby(pd.Grouper(freq='1H'))['score'].sum()\n",
    "print(tweets_grouped)\n",
    "tweets_grouped.to_csv('data/twitter/BTC/bitcoin_tweets_grouped.csv')\n",
    "crypto_usd['time'] = pd.to_datetime(crypto_usd['time'], unit='s')\n",
    "crypto_usd.index = crypto_usd['time']\n",
    "\n",
    "crypto_usd_grouped = crypto_usd.groupby(pd.Grouper(freq='1H'))['close'].mean()\n",
    "\n",
    "print(crypto_usd_grouped)\n",
    "crypto_usd_grouped.to_csv('data/crypto/BTC/bitcoin_currency_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the scores\n",
    "We calculate the mean of each tweets grouped by hour and then we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Crypto currency evolution compared to twitter sentiment\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped.index, tweets_grouped, 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped.index, crypto_usd_grouped, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment\", color='g', fontsize=16)\n",
    "ax2.set_ylabel(f\"{CURRENCY_SYMBOL} [$]\", color='b', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis\n",
    "Here we make the correlation analysis between BTC/USD currency derivative and the tweets scores derivative.\n",
    "\n",
    "We can test our correlation hypothesis using the Pandas corr() method, which computes a Pearson correlation coefficient for each column in the dataframe against each other column.\n",
    "\n",
    "This Stackoverflow answer gives very useful details about correlating with time series.\n",
    "https://stackoverflow.com/questions/6467832/how-to-get-the-correlation-between-two-timeseries-using-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cross-correlation function\n",
    "\n",
    "def crosscorr(datax, datay, lag=0, method=\"pearson\"):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Parameters\n",
    "    â€”------â€”\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    â€”------â€”\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    return datax.corr(datay.shift(lag), method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the time series to match the time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beggining = max(tweets_grouped.index.min(), crypto_usd_grouped.index.min())\n",
    "end = min(tweets_grouped.index.max(), crypto_usd_grouped.index.max())\n",
    "tweets_grouped = tweets_grouped[beggining:end]\n",
    "crypto_usd_grouped = crypto_usd_grouped[beggining:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Crypto currency evolution compared to twitter sentiment\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped.index, tweets_grouped, 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped.index, crypto_usd_grouped, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment\", color='g', fontsize=16)\n",
    "ax2.set_ylabel(f\"{CURRENCY_SYMBOL} [$]\", color='b', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_grouped.T.corr(crypto_usd_grouped, method='pearson')\n",
    "#tweets_grouped.T.autocorr(crypto_usd_grouped, lag=20)\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"pearson\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"pearson cross-correlation\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"kendall\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"kendall cross-correlation\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"spearman\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"spearman cross-correlation\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize \n",
    "First we need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize time series data\n",
    "tweets_grouped = tweets_grouped / max(tweets_grouped.max(), abs(tweets_grouped.min()))\n",
    "crypto_usd_grouped = crypto_usd_grouped / max(crypto_usd_grouped.max(), abs(crypto_usd_grouped.min()))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Normalized Crypto currency evolution compared to normalized twitter sentiment\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped.index, tweets_grouped, 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped.index, crypto_usd_grouped, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment\", color='g', fontsize=16)\n",
    "ax2.set_ylabel(f\"{CURRENCY_SYMBOL} normalized\", color='b', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_grouped.T.corr(crypto_usd_grouped, method='pearson')\n",
    "#tweets_grouped.T.autocorr(crypto_usd_grouped, lag=20)\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i) for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"lag's impact on correlation (normalized)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate derivative\n",
    "\n",
    "The derivative is calculated to define an increase or a decrease of the crypto currency.\n",
    "\n",
    "The score is as well derivated to observe the increase or decrease of the score.\n",
    "\n",
    "Computing the derivative could help to find a correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative\n",
    "tweets_grouped = pd.Series(np.gradient(tweets_grouped.values), tweets_grouped.index, name='slope')\n",
    "crypto_usd_grouped = pd.Series(np.gradient(crypto_usd_grouped.values), crypto_usd_grouped.index, name='slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(\"Derivative of crypto currency and sentiment's score\", fontsize=18)\n",
    "ax1.tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot_date(tweets_grouped.index, tweets_grouped, 'g-')\n",
    "ax2.plot_date(crypto_usd_grouped.index, crypto_usd_grouped, 'b-')\n",
    "\n",
    "ax1.set_ylabel(\"Sentiment's derivative\", color='g', fontsize=16)\n",
    "ax2.set_ylabel(f\"{CURRENCY_SYMBOL}'s derivative'\", color='b', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"pearson\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"pearson cross-corelation (derivative)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"kendall\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"kendall cross-corelation (derivative)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()\n",
    "\n",
    "xcov = [crosscorr(tweets_grouped, crypto_usd_grouped, lag=i, method=\"spearman\") for i in range(-20,20)]\n",
    "plt.plot(range(-20,20), xcov)\n",
    "plt.title(\"spearman cross-corelation (derivative)\")\n",
    "plt.xlabel(\"lag\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realtime correlation viewer\n",
    "We can stream the new tweets about the crypto using the TwythonStreamer module. \n",
    "\n",
    "Using the CryptoCompare API we can also retrieve the crypto currency in realtime using sockets.\n",
    "\n",
    "Finally we can plot it with Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update historical data until today\n",
    "file = open(\"current_crypto.txt\", \"w\") \n",
    "file.write(CURRENCY_SYMBOL)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_data_from_csv(folder, n_rows):\n",
    "    '''\n",
    "    @ folder : relative path where the data is contained\n",
    "    @ n_rows : the number of rows to retrieve up to the most recent ones\n",
    "    \n",
    "    Return a dataframe containing n_rows of the most recent data retrieved\n",
    "    '''\n",
    "    files =  glob.glob(f\"{folder}/*.csv\")\n",
    "    files = sorted(files)\n",
    "    df = pd.DataFrame()\n",
    "    for file in reversed(files):\n",
    "        print(file)\n",
    "        df = df.append(pd.read_csv(file))\n",
    "        if df.shape[0] > n_rows:\n",
    "            break\n",
    "    return df.sort_values(by=['time']).tail(n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import chart_studio.tools as tls \n",
    "# Get stream id from stream id list\n",
    "\n",
    "stream_id_crypto, stream_id_tweets = tls.get_credentials_file()['stream_ids'][:2]\n",
    "print(stream_id_tweets)\n",
    "print(stream_id_crypto)\n",
    "# Make instance of stream id object \n",
    "stream_tweets = go.scatter.Stream(\n",
    "    token=stream_id_tweets,  # link stream id to 'token' key\n",
    "    maxpoints=80      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "stream_crypto = go.scatter.Stream(\n",
    "    token=stream_id_crypto,  # link stream id to 'token' key\n",
    "    maxpoints=80      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "# Initialize trace of streaming plot by embedding the unique stream_id\n",
    "trace_tweets = go.Scatter(x=[], y=[], mode='lines', name='Sentiments', stream=stream_tweets)\n",
    "\n",
    "CRYPTO_FOLDER = \"data/crypto/\"+CURRENCY_SYMBOL\n",
    "crypto_usd_updated = get_most_recent_data_from_csv(CRYPTO_FOLDER, 10000)\n",
    "# Drop duplicates\n",
    "crypto_usd_updated = crypto_usd_updated.drop_duplicates(subset=['time'])\n",
    "trace_crypto = go.Scatter(x=crypto_usd_updated['time'].tail(200).apply(lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S')),\n",
    "                          y=crypto_usd_updated['close'].tail(200), yaxis='y2', stream=stream_crypto, name = CURRENCY_SYMBOL)\n",
    "\n",
    "#data = [trace_crypto, trace_tweets]\n",
    "data = [trace_crypto, trace_tweets]\n",
    "\n",
    "# Add title to layout object\n",
    "layout = go.Layout(\n",
    "    title=CURRENCY_SYMBOL +\"currency and tweets sentiments\",\n",
    "    legend=dict(orientation=\"h\"),\n",
    "    yaxis=dict(\n",
    "        title='Sentiment score',\n",
    "        titlefont=dict(\n",
    "            color='rgb(255, 119, 0)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            color='rgb(255, 119, 0)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='{CURRENCY_SYMBOL} Price ($ USD)',\n",
    "        titlefont=dict(\n",
    "            color='rgb(33, 118, 180)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            color='rgb(33, 118, 180)'\n",
    "        ),\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Make a figure object\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename=f\"real_time_{CURRENCY_SYMBOL}_tweets\", fileopt=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before continuing, run the crypto streamer first\n",
    "\n",
    "Open your terminal and execute this command at the same level as this notebook. You first need to have [npm with node](https://www.npmjs.com/get-npm) installed on your machine.\n",
    "\n",
    "- `cd streamer && npm install && node stream_crypto.js`\n",
    "\n",
    "Altenrativaley, you can run this line inside a jupyter notebook but it makes the cell block \n",
    "\n",
    "- `! cd streamer && npm install && node stream_crypto.js`\n",
    "\n",
    "### Once the crypto streamer is run you can run the following cell to stream the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# We will provide the stream link object the same token that's associated with the trace we wish to stream to\n",
    "#s_crypto = py.Stream(stream_id_crypto)\n",
    "stream_id_tweets='ap94vi23vv'\n",
    "#s_tweets = py.Stream(stream_id_tweets)\n",
    "\n",
    "# We then open a connection\n",
    "#s_crypto.open()\n",
    "#s_tweets.open()\n",
    "\n",
    "s_tweets = go.scatter.Stream(\n",
    "    token=stream_id_tweets,  # link stream id to 'token' key\n",
    "    maxpoints=80      # keep a max of 80 pts on screen\n",
    ")\n",
    "\n",
    "\n",
    "# Vader sentiment analyser\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    def on_success(self, data):\n",
    "        if 'text' in data:\n",
    "            # x value: date\n",
    "            date_str = data['created_at']\n",
    "            time_struct = time.strptime(date_str, \"%a %b %d %H:%M:%S +0000 %Y\")#Tue Apr 26 08:57:55 +0000 2011\n",
    "            date = datetime.fromtimestamp(time.mktime(time_struct))\n",
    "            date = date + timedelta(hours=4) # hack to sync tweet's date to current time\n",
    "            \n",
    "            # y value: sentiment of the tweet\n",
    "            text = data['text']\n",
    "            vs = analyzer.polarity_scores(text)\n",
    "            score = vs[\"compound\"] * (data[\"user\"][\"followers_count\"]+1) * (data[\"favorite_count\"]+1)\n",
    "            #print(date, score)\n",
    "            s_tweets.write(dict(type='scatter',\n",
    "                 x=date,y=score))\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "\n",
    "        # Want to stop trying to get data because of the error?\n",
    "        # Uncomment the next line!\n",
    "        # self.disconnect()\n",
    "        \n",
    "APP_KEY = 'mPQKoRwd2Pb9qpQyQmyG5s8KR'\n",
    "APP_SECRET = 'HLvIhusvfzDLKaRXY8CnZGP143kp3E3f2KqQBIEMfVL5mOxZjq'\n",
    "OAUTH_TOKEN = \"3459248236-0XPtHldG3ou6BfpTwaKWnOL2ywFk2niQekLwE7K\"\n",
    "OAUTH_TOKEN_SECRET = \"08Vy2wuOkp7AmuC3rbjCHFJ94MLG2sWqdvGQtoiXmkVKr\"\n",
    "\n",
    "stream = MyStreamer(APP_KEY, APP_SECRET,OAUTH_TOKEN, OAUTH_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To stop the real time data retrieving, stop the kernel in this notebook and press Ctrl+C in your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the stream when done plotting\n",
    "s_tweets.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
